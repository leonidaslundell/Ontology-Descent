---
title: "Benchmarking various ontological packages, distances and clustering method "
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction & aims

There are three distinct components in this project (existing methods): 

1. Ontological distance metric (Graphd distance, Wang, Resnik etc).
2. Clustering component.
3. Overall, final result (package component, eg Revigo).

GO input terms benchmarking should be consider size (ranging from large to small) and diversity (similar go terms vs dissimilar go terms). Another consideration (further down the line) is clustering behavior with MF & BP & CC combined or separate. 

One big issue with test data is ground truth data. I might have come up with a solution for generating that...

Outline of approach: 

* Validate that the synthetic data look sufficiently diverse.
* Compare public data to the synthetic data
* Figure out appropriate metric for method comparison of synthetic data
* Use public data of to perform camera enrichment and visually inspect the results comparing our method to simplify enrichment.

Quick note: simplify enrichment is not the gold standard. It is a wrapper for several distance and clustering metrics, and it also presents a novel clustering method. I initially only test their novel method, but further down the line i want to benchmark all distance, and all clustering methods against our method. 

# Data

simplifyEnrichment package has a random GO generator with size. The fact that you get clusters from random data is problematic. I **might** have developed a meaningfull GO tree sampler.

For real data i will use the ~30 microarray experiments from the KEGG topological pathway analaysis tools.

## Introduction to data generation

Briefly, generating a clustered ontology dataset is based using the fact that GO terms are ontological. Take a cutree at a sampled height (or rather k), take a sample from the branch, and you have a cluster. This will give you both broad and specific clusters (as you end up cutting randomly). You also known that a certain bunch of ontology terms are related as they have originated from the same tree. This approach **does not** preclude though that different trees are related as you might cut from the same tree upstream or parallel.

One major issue with using this data as ground truth is that its hard to link up the resulting cluster with the originating cluster: ie. you get 50 predicted clusters, which one of all (and perhaps which many of all) are linking to the any one of the test data clusters? My mediocre solution to this is to take a *best fit* approach where you match the generated cluster with the originating clusters based on jackard index (intersect/union). A jackard index of 1 means a perfect fit.

Another major consideration: am i shooting an arrow on the wall and painting a bullseye after the fact? Is the tree data i generate a realistic representaion of reality?

## Generating tree data

```{r, message=FALSE}
source("R/networkGeneratoR.R")
source("R/sampleR.R")
source("R/clustereR.R")
library(org.Hs.eg.db)
library(simplifyEnrichment)
library(igraph)
library(ggplot2)
library(data.table)
library(patchwork)
```


```{r}
# net <- networkeR(ont = "MF")
# 
# distNet <- distances(net)
# clustNet <- hclust(as.dist(distNet))
# 
# GOlength <- sapply(as.list(org.Hs.egGO2ALLEGS), length)
# GOnames <- as.list(GO.db::GOTERM)
# GOnames <- sapply(GOnames, Term)
# 
# save(list = c("net", "distNet", "clustNet", "GOlength", "GOnames", "GOnames"), 
#      file = "data/dataClustereR.Rdata")

load("data/dataClustereR.Rdata")
```

<!-- Generate 1000 different samples and test various summary statistics of it. -->

<!-- ```{r} -->
<!-- test <- lapply(1:50, sampleR, ontoHclust = clustNet) -->
<!-- test <- test[sapply(test, length)>0] -->
<!-- test2 <- sapply(test, function(x){ -->
<!--   sapply(x, length) -->
<!-- }) -->

<!-- test2 <- reshape2::melt(test2) -->
<!-- colnames(test2) <- c("clusterSize", "sample") -->

<!-- test2 <- as.data.table(test2) -->

<!-- ggplot(test2, aes(x = clusterSize, group = sample, color = as.character(sample))) + -->
<!--   geom_density() + -->
<!--   xlab("Cluster sizes in each sample")+ -->
<!--   theme(legend.position = "none") -->

<!-- par(mfrow=c(2,2)) -->
<!-- hist(sapply(test, length), main = "Number of clusters in each sample", xlab = "") -->

<!-- hist(test2[,median(clusterSize), by = "sample"]$V1, -->
<!--      main = "Median size of cluster \nin each generated sample", -->
<!--      xlab = "" -->
<!-- ) -->

<!-- hist(test2[,max(clusterSize), by = "sample"]$V1, -->
<!--   main = "Max size of cluster \nin each generated sample", -->
<!--   xlab = "", -->
<!--   breaks = 7 -->
<!-- ) -->

<!-- test <- sapply(test, function(x){ -->
<!--   unique(unlist(x)) -->
<!-- }) -->

<!-- hist(sapply(test, length), main = "Number of unique GO terms\nin each sample", breaks = 20) -->

<!-- # UpSetR::upset(UpSetR::fromList(test[3:5])) -->

<!-- ``` -->

<!-- Do they look sufficiently different? Yeah think so... -->

<!-- Overall plausible: many small clusters (one offs, and fewer big clusters). -->

## Generating 1000 samples of synthetic data

```{r}
# test <- lapply(1:1000, function(n){
#   print(n)
#   sampleR(ontoHclust = clustNet, n = sample(5:50,1))
# })
# save(test, file = "data/1000sampleR.Rdata")
# test <- test[sapply(test, length)>0]

load("data/1000sampleR.Rdata")

```

Have not investigated the effect of number of k taken for sampleR function. Current implementation is:
sample(20:1000,1), but maybe we can make more realistic data with different parameters?

## Generating real GO data

 Camera analysis for GO terms

```{r}
# library(limma)
# library(KEGGandMetacoreDzPathwaysGEO)
# library(KEGGdzPathwaysGEO)
# library(Biobase)
# library(hgu133plus2.db)
# library(hgu133a.db)
# library(annotate)
# 
# data("GSE1145")
# 
# plus2 <- as.list(hgu133plus2ENTREZID)
# sum(!rownames(GSE1145) == names(plus2))
# names(plus2)[!rownames(GSE1145) == names(plus2)]
# #some afymetrix specific stuff.
# 
# data("GSE1297")
# a <- as.list(hgu133aENTREZID)
# sum(!rownames(GSE1297) == names(a))
# names(a)[!rownames(GSE1297) == names(a)]
# 
# x <- as.list(org.Hs.egGO2ALLEGS)
# plus2 <- ids2indices(gene.sets = x,identifiers = unlist(plus2))
# a <- ids2indices(gene.sets = x,identifiers = unlist(a))
# 
# mysets <- c(data(package="KEGGandMetacoreDzPathwaysGEO")$results[,"Item"],
#             data(package="KEGGdzPathwaysGEO")$results[,"Item"])
# 
# resCamera <- NULL
# 
# for(gse in mysets){
#   print(gse)
# 
#   eval(parse(text = paste0("data(", gse, ")")))
#   eval(parse(text = paste0("dat <- ", gse)))
#   eval(parse(text = paste0("rm(", gse, ")")))
#   
#   resCamera[[gse]] <- "NA"
#   
#   if(annotation(dat) == "hgu133plus2")
#     resCamera[[gse]] <- camera(exprs(dat), plus2, model.matrix(~0 + Group, dat))
# 
#   if(annotation(dat) == "hgu133a")
#     resCamera[[gse]] <- camera(exprs(dat), a, model.matrix(~0 + Group, dat))
# 
# }

# save(resCamera, file = "data/PublicGSEdata_GOcamera.Rdata")
load("data/PublicGSEdata_GOcamera.Rdata")
```

## Comparing the shape and properties of the real GO data and the synthetic data

### Summary statistics of real GO terms

```{r}
resCamera <- lapply(resCamera, function(x){
  x <- rownames(x[x$FDR<0.05,])
  x[x %in% V(net)$name] #keeping only MF
})
```

Remove maps without any results.

```{r}
resCamera <- resCamera[sapply(resCamera, length)>1]
```

### Distances of GO - GO terms

```{r}
resCameraDist <- lapply(resCamera, function(x){
  temp <- distances(net, x, x)
  temp <- reshape2::melt(temp[upper.tri(temp)])
  temp$value
})

resCameraDist <- reshape2::melt(resCameraDist)
resCameraDist <- as.data.table(resCameraDist)

testDist <- lapply(test[sample(1:length(test), 200, replace = F)], function(x){
  x <- unique(unlist(x))
  temp <- distances(net, x, x)
  temp <- reshape2::melt(temp[upper.tri(temp)])
  temp$value
})
testDist <- reshape2::melt(testDist)
testDist <- as.data.table(testDist)
```

This is actually quite a difference at 9 (ie synthetic data seems to have a slightly larger distance between its terms?)

### Are the graph parameters different between the synthetic and the real data?

```{r}
suppressWarnings({
  resCameraParameters <- sapply(resCamera, function(n){
  indNet <- induced_subgraph(net, vids = unique(unlist(n)))
  c(degree = centr_degree(indNet)$centralization,
    betw = centr_betw(indNet)$centralization,
    clo = centr_clo(indNet)$centralization,
    eig = centr_eigen(indNet)$centralization,
    componenets = count_components(indNet),
    diameters = diameter(indNet))
})
#warning suppresed is that closseness is not well defined for disconnected graphs

testParamerters <- sapply(test, function(n){
  indNet <- induced_subgraph(net, vids = unique(unlist(n)))
  c(degree = centr_degree(indNet)$centralization,
    betweenness = centr_betw(indNet)$centralization,
    closeness = centr_clo(indNet)$centralization,
    eigen = centr_eigen(indNet)$centralization,
    componenets = count_components(indNet),
    diameters = diameter(indNet))
})
})


resCameraParameters <- reshape2::melt(resCameraParameters)
resCameraParameters$Var2 <- as.numeric(resCameraParameters$Var2)

testParamerters <- reshape2::melt(testParamerters)
testParamerters <- rbind(cbind(resCameraParameters, data = "real"),
                         cbind(testParamerters, data = "synthetic"))
testParamerters <- as.data.table(testParamerters)

```

### Comparing the synthetic data and real data structures and large scale properties

```{r}

#number of unique terms
par(mfrow=c(2,1))
hist(sapply(resCamera, function(GO) length(GO)), main = "Real data", xlab = "Number of GO terms", xlim = c(0, 1200))
hist(sapply(test, function(GO) length(unique(unlist(GO)))), main = "Synthetic data", xlab = "Number of GO terms", xlim = c(0, 1200))

#distance of all to all

resCameraDist <- rbind(cbind(resCameraDist, data = "Real"),
                       cbind(testDist, data = "Synthetic"))

ggplot(resCameraDist[,median(value), by = c("L1", "data")], aes(x = V1, color = data, group = data)) +
  geom_density(show.legend = T) +
  xlab("Distance of all to all in sample") +
  ggtitle("Median") +
ggplot(resCameraDist[,max(value), by = c("L1", "data")], aes(x = V1, color = data, group = data)) +
  geom_density(show.legend = T) +
  xlab("Distance of all to all in sample") +
  ggtitle("Max") +
  plot_layout(guides = "collect")

#graph structure
ggplot(testParamerters, aes(x = value, group = Var2)) +
  geom_histogram() +
  facet_grid(data~Var1, scales = "free")

```

What do the different graph measures mean? 

* Degree score for a node - simplest score, how many nodes do you connect to.
* Betweenness score for a node - how many shortest paths between all pairs of vertices pass through a given vertex.
* Closenes score for a node - 1/sum(length to all vertices from a node). Calculates how close you are to everything.
* Eigenvector score for a node - linear algebra mathemagic that tells you whether a node connects to other well connected nodes. Gangster nodes basically.
* Diameter of a graph - what is the biggest shortest path in the graph
* Components of a graph - how many isolated islands does a graph have. Counts single isolated vertices as well.

And a nice wikipedia figure:


```{r, echo=FALSE, fig.cap="Examples of A) Betweenness centrality, B) Closeness centrality, C) Eigenvector centrality, D) Degree centrality, E) Harmonic centrality and F) Katz centrality of the same graph", out.width = '100%'}
knitr::include_graphics("https://upload.wikimedia.org/wikipedia/commons/1/11/6_centrality_measures.png")
```

<!-- # Testing clusterer vs simplifyEnrichment -->

<!-- The following code is trying to figure out which metrics are *meassurable/good* for one cluster, preferably in one simple quantifiable number in order to be able to objectively compare the performance of various clustering and distance algorithms. -->

<!-- Using the sampler funcion to compare simplifyEnrichment and clutereR -->

<!-- ```{r} -->

<!-- test <- sampleR(clustNet) -->
<!-- summary(sapply(test, length)) -->

<!-- resClust <- clustereR(net, GOnames, GOlength, unique(unlist(test))) -->
<!-- resSimpl <- simplifyEnrichment(GO_similarity(unique(unlist(test)), ont = "MF"), plot = F) -->

<!-- plot(density(table(resClust$cluster)), col = "red", main = "cluster size") -->
<!-- lines(density(table(resSimpl$cluster))) -->
<!-- ``` -->

<!-- Seems to be higher diveristy in the graph based. Simplify enrichmnet gives you fewer bigger clusters, and a ton of non clustered. Graph based clustering gives you bigger number but smaller... Compare this to the known distribution from the originating data. -->

<!-- ```{r} -->
<!-- resSimpl <- lapply(unique(resSimpl$cluster), function(i){ -->
<!--   resSimpl$id[resSimpl$cluster == i] -->
<!-- }) -->
<!-- resSimpl <- resSimpl[order(sapply(resSimpl, length), decreasing = T)] -->

<!-- resClust <- lapply(unique(resClust$cluster), function(i){ -->
<!--   resClust$ontoID[resClust$cluster == i] -->
<!-- }) -->
<!-- resClust <- resClust[order(sapply(resClust, length), decreasing = T)] -->

<!-- plot(density(table(sapply(test, length))), col = "blue", ylim = c(0,1), main = "Cluster size") -->
<!-- lines(density(table(sapply(resClust, length))), col = "red") -->
<!-- lines(density(table(sapply(resSimpl, length)))) -->

<!-- ``` -->

<!-- Neither seem to follow the size of the ground truth particular well. -->

<!-- Its hard to connect the cluster generated with the originating cluster. Best i can come up with is jackard index of all generated clusters to all original clusters and taking the maximal value as the "match". -->

<!-- ```{r} -->
<!-- resSimplJackInd <- sapply(test, function(yy){ -->
<!--   sapply(resSimpl, function(xx){ -->
<!--     length(intersect(xx, yy))/length(unique(c(xx, yy))) -->
<!--   }) -->
<!-- }) -->

<!-- resClustJackInd <- sapply(test, function(yy){ -->
<!--   sapply(resClust, function(xx){ -->
<!--     length(intersect(xx, yy))/length(unique(c(xx, yy))) -->
<!--   }) -->
<!-- }) -->

<!-- ``` -->

<!-- Taking also the absolute sum. -->

<!-- ```{r} -->
<!-- resSimplSum <- sapply(test, function(yy){ -->
<!--   sapply(resSimpl, function(xx){ -->
<!--     length(intersect(xx, yy)) -->
<!--   }) -->
<!-- }) -->

<!-- resClustSum <- sapply(test, function(yy){ -->
<!--   sapply(resClust, function(xx){ -->
<!--     length(intersect(xx, yy)) -->
<!--   }) -->
<!-- }) -->

<!-- ``` -->

<!-- Rows give the predictions, columns the original cluster. How many different resulting clusters point to the same ground truth cluster? -->

<!-- ```{r} -->
<!-- hist(sort(table(apply(resClustJackInd, 1, which.max))),  -->
<!--      main = "How many different clusters generated\npoint to the same original", -->
<!--      xlab = "ClusereR") -->
<!-- hist(sort(table(apply(resSimplJackInd, 1, which.max))), -->
<!--      main = "How many different clusters generated\npoint to the same original", -->
<!--      xlab = "simplifyEnrichment") -->
<!-- ``` -->

<!-- Allot different clusters point to the same cluster for simplify enrichment. -->

<!-- Check how many hits have a good Jackard Index fit (for n > 2 in length) -->

<!-- ```{r} -->
<!-- apply(resSimplJackInd[sapply(resSimpl, length)>2,], 1, max) -->
<!-- apply(resClustJackInd[sapply(resClust, length)>2,], 1, max) -->

<!-- ``` -->

<!-- What is the relationship between cluster size and jackard index? -->

<!-- ```{r} -->
<!-- par(mfrow=c(1,2)) -->
<!-- plot(sapply(resSimpl, length)[sapply(resSimpl, length)>2], -->
<!--      apply(resSimplJackInd[sapply(resSimpl, length)>2,], 1, max), type = "b",  -->
<!--      xlab = "Cluster size", ylab = "Jackard Index of cluster", -->
<!--      main = "SimplifyEnrichment size ~ jackard", cex =.4) -->

<!-- plot(sapply(resClust, length)[sapply(resClust, length)>2], -->
<!--      apply(resClustJackInd[sapply(resClust, length)>2,], 1, max), type = "b",  -->
<!--      xlab = "Cluster size", ylab = "Jackard Index of cluster", -->
<!--      main = "ClustereR size ~ jackard", cex =.4) -->

<!-- ``` -->

<!-- <!-- How many GO terms are covered by good quality clusters? --> -->

<!-- <!-- ```{r} --> -->
<!-- <!-- resClustJackIndWhich <- apply(resClustJackInd[sapply(resClust, length)>2,], 1, max) --> -->
<!-- <!-- resClustJackIndWhich <- resClustJackIndWhich>.5 --> -->

<!-- <!-- resSimplJackIndWhich <- apply(resSimplJackInd[sapply(resSimpl, length)>2,], 1, max) --> -->
<!-- <!-- resSimplJackIndWhich <- resSimplJackIndWhich>.5 --> -->

<!-- <!-- #this is wrong... --> -->
<!-- <!-- sum(resSimplSum[sapply(resSimpl, length)>2, resSimplJackIndWhich]) --> -->
<!-- <!-- sum(resClustSum[sapply(resClust, length)>2, resClustJackIndWhich]) --> -->

<!-- <!-- ``` --> -->


<!-- <!-- # Test different distances --> -->

<!-- <!-- ## Ontology Descent approach simple outline --> -->

<!-- <!-- Ontology Descent has 4 steps: --> -->

<!-- <!-- * Get the graph distance (Lars suggests to add the Jackard index to edge) --> -->
<!-- <!-- * Cluster the graph and cut the graph (right now simple tree cutting at discrete intervals) --> -->
<!-- <!-- * Some kind of metric for the clustering at each discrete interval cut --> -->
<!-- <!-- * User decides, based on the metric provided, the number of clusters. --> -->

<!-- <!-- The main challenge for benchmarking is that currently the method is subjective, and its impossible to compare to the automatic methods. --> -->

<!-- <!-- Applying current itteration of method to the data. --> -->

<!-- <!-- Loading function and setting up the data: --> -->

<!-- <!-- ```{r} --> -->
<!-- <!-- source("R/clustereR.R") --> -->
<!-- <!-- source("R/networkGeneratoR.R") --> -->
<!-- <!-- library(org.Mm.eg.db) --> -->

<!-- <!-- GOlength <- sapply(as.list(org.Mm.egGO2ALLEGS), length) --> -->
<!-- <!-- GOnames <- as.list(GO.db::GOTERM) --> -->
<!-- <!-- GOnames <- sapply(GOnames, Term) --> -->

<!-- <!-- net <- networkeR(ont = "BP") --> -->

<!-- <!-- ``` --> -->

<!-- <!-- Run the latest version of the clusterer --> -->

<!-- <!-- ```{r} --> -->
<!-- <!-- goClust <- clustereR(net, ontoNames = GOnames, ontoLength = GOlength, goBench$SmallReal) --> -->

<!-- <!-- ``` --> -->


<!-- <!-- ## Distance --> -->

<!-- <!-- simplifyEnrichment easily calculates the standard "Wang", "Resnik", "Rel", "Jiang", and "Lin" distance methods. It also provides an automatic clusterig method. Use this to investigate how good the simple step distance metric is. --> -->

<!-- <!-- ```{r} --> -->
<!-- <!-- library(simplifyEnrichment) --> -->

<!-- <!-- goDist <- lapply(goBench, function(dat){ --> -->
<!-- <!--   goDistInt <- lapply(c("Wang", "Resnik", "Rel", "Jiang","Lin"), function(mea){ --> -->
<!-- <!--     GO_similarity(dat, ont = "BP", measure = mea) --> -->
<!-- <!--   }) --> -->
<!-- <!--   names(goDistInt) <- c("Wang", "Resnik", "Rel", "Jiang","Lin") --> -->

<!-- <!--   goDistInt --> -->
<!-- <!-- }) --> -->
<!-- <!-- ``` --> -->

<!-- <!-- ## Clustering --> -->

<!-- <!-- Default of simplifyEnrichment is binary cut, but lets do all. --> -->

<!-- <!-- ```{r} --> -->
<!-- <!-- library(ggplot2) --> -->

<!-- <!-- compare_clustering_methods(goDist$SmallRand$Descent,  --> -->
<!-- <!--                            all_clustering_methods()[-c(10,4)]) --> -->

<!-- <!-- goClust <- lapply(all_clustering_methods(), function(meth){ --> -->
<!-- <!--   lapply(goDist, function(dist){ --> -->
<!-- <!--     simplifyGO(mat = dist, plot = F, method = meth) --> -->
<!-- <!--   }) --> -->
<!-- <!-- }) --> -->
<!-- <!-- names(goClust) <- all_clustering_methods() --> -->

<!-- <!-- print("Number of clusters per distance metric") --> -->
<!-- <!-- sapply(goClust, function(dist) length(unique(dist$cluster))) --> -->
<!-- <!-- print("Size of cluster per distance metric") --> -->
<!-- <!-- sapply(goClust, function(dist) table(dist$cluster)) --> -->
<!-- <!-- ``` --> -->

<!-- <!-- Many small cluster with both Rel and Jiang. Dumb distance metric gives only 1 cluster. --> -->

